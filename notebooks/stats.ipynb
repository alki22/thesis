{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = '../../resources/corpora/sensem.conll'\n",
    "\n",
    "metadata_cols = ['META', 'sentence', 'corpus', 'main_lemma', 'main_lemma_index',\n",
    "                 'resource_sentence', 'sense', 'wn', 'wn16', 'wn30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = '../../resources/corpora/semeval.conll'\n",
    "\n",
    "metadata_cols = ['META', 'sentence', 'corpus', 'doc', 'lemma_tag', 'main_lemma',\n",
    "                 'main_lemma_index', 'resource_sentence', 'sense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata = []\n",
    "for mdata in sh.grep('^META', input_file):\n",
    "    metadata.append(dict(md.split(':', 1) for md in mdata.strip().split()))\n",
    "\n",
    "metadata = pd.DataFrame(metadata, columns=metadata_cols)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_filter_condition = (metadata.corpus != 'filtered') & (metadata.lemma_pos == 'v')\n",
    "train_condition = (metadata.corpus == 'train') & (metadata.lemma_pos == 'v')\n",
    "test_condition = (metadata.corpus == 'test') & (metadata.lemma_pos == 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_filter_condition = (metadata.corpus != 'filtered')\n",
    "train_condition = (metadata.corpus == 'train')\n",
    "test_condition = (metadata.corpus == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Sentences: %d\" % metadata.sentence.count())\n",
    "print(\"Filtered: %d\" % metadata[~not_filter_condition].sentence.count())\n",
    "print(\"Training: %d\" % metadata[train_condition].sentence.count())\n",
    "print(\"Test: %d\" % metadata[test_condition].sentence.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Avg. sentences per lemma: %.2f\" % metadata[not_filter_condition]\n",
    "      .groupby([lemma_column]).count().sentence.mean())\n",
    "print(\"Median sentences per lemma: %.2f\" % metadata[not_filter_condition]\n",
    "      .groupby([lemma_column]).count().sentence.median())\n",
    "print(\"Avg. sentences per sense: %.2f\" % metadata[not_filter_condition]\n",
    "      .groupby([lemma_column, sense_column]).count().sentence.mean())\n",
    "print(\"Median sentences per sense: %.2f\" % metadata[not_filter_condition]\n",
    "      .groupby([lemma_column, sense_column]).count().sentence.median())\n",
    "\n",
    "print(\"Avg. sentences per lemma for train: %.2f\" % metadata[train_condition]\n",
    "      .groupby([lemma_column]).count().sentence.mean())\n",
    "print(\"Avg. sentences per lemma for test: %.2f\" % metadata[test_condition]\n",
    "      .groupby([lemma_column]).count().sentence.mean())\n",
    "print(\"Avg. sentences per sense for train: %.2f\" % metadata[train_condition]\n",
    "      .groupby([lemma_column, sense_column]).count().sentence.mean())\n",
    "print(\"Avg. sentences per sense for test: %.2f\" % metadata[test_condition]\n",
    "      .groupby([lemma_column, sense_column]).count().sentence.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"No. of lemmas: %d\" % metadata[not_filter_condition][lemma_column].nunique())\n",
    "print(\"No. of senses: %d\" % metadata[not_filter_condition]\n",
    "      .groupby([lemma_column, sense_column])[sense_column].nunique().sum())\n",
    "print(\"Avg. no. of senses per lemma: %.2f\" % metadata[not_filter_condition]\n",
    "      .groupby([lemma_column])[sense_column].nunique().mean())\n",
    "print(\"Median no. of senses per lemma: %.2f\" % metadata[not_filter_condition]\n",
    "      .groupby([lemma_column])[sense_column].nunique().median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics for Semeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = '../../resources/corpora/semeval.conll'\n",
    "\n",
    "sentences = []\n",
    "with open(input_file, 'r') as fin:\n",
    "    for line in fin:\n",
    "        if line.startswith('META'):\n",
    "            sentences.append(dict(w.split(':', 1) for w in line.strip().split()))\n",
    "\n",
    "sentences = pd.DataFrame(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences['sense_sentence_count'] = sentences\\\n",
    "    .groupby(['main_lemma', 'sense'])['sentence'].transform('count')\n",
    "\n",
    "sentences['lemma_sentence_count'] = sentences\\\n",
    "    .groupby(['main_lemma'])['sentence'].transform('count')\n",
    "    \n",
    "sentences['sense_count'] = sentences\\\n",
    "    .groupby(['main_lemma'])['sense']\\\n",
    "    .transform(lambda x: x.nunique())\n",
    "\n",
    "sentences['senses_over_threshold'] = sentences['main_lemma']\\\n",
    "    .map(sentences.groupby('main_lemma')\\\n",
    "    .apply(lambda x: x.loc[x.sense_sentence_count >= 3, 'sense'].nunique()))\n",
    "\n",
    "sentences['is_valid'] = (sentences['senses_over_threshold'] > 1) & (sentences['sense_sentence_count'] >= 3) &\\\n",
    "    (sentences['lemma_tag'] == 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Statistics per lemma\")\n",
    "print(sentences[sentences.is_valid].groupby(['main_lemma']).first()['lemma_sentence_count'].describe())\n",
    "\n",
    "print(\"\\nStatistics per sense\")\n",
    "print(sentences[sentences.is_valid].groupby(['main_lemma', 'sense']).first()['sense_sentence_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics for Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = '../../resources/corpora/google_wsd.conll.new'\n",
    "\n",
    "sentences = []\n",
    "with open(input_file, 'r') as fin:\n",
    "    for line in fin:\n",
    "        if line.startswith('META'):\n",
    "            sentences.append(dict(w.split(':', 1) for w in line.strip().split()))\n",
    "\n",
    "sentences = pd.DataFrame(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences['sense_sentence_count'] = sentences\\\n",
    "    .groupby(['main_lemma', 'sense'])['sentence'].transform('count')\n",
    "\n",
    "sentences['lemma_sentence_count'] = sentences\\\n",
    "    .groupby(['main_lemma'])['sentence'].transform('count')\n",
    "    \n",
    "sentences['sense_count'] = sentences\\\n",
    "    .groupby(['main_lemma'])['sense']\\\n",
    "    .transform(lambda x: x.nunique())\n",
    "\n",
    "sentences['senses_over_threshold'] = sentences['main_lemma']\\\n",
    "    .map(sentences.groupby('main_lemma')\\\n",
    "    .apply(lambda x: x.loc[x.sense_sentence_count >= 3, 'sense'].nunique()))\n",
    "\n",
    "sentences['is_valid'] = (sentences['senses_over_threshold'] > 1) & (sentences['sense_sentence_count'] >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Statistics per lemma\")\n",
    "print(sentences[sentences.is_valid].groupby(['main_lemma']).first()['lemma_sentence_count'].describe())\n",
    "\n",
    "print(\"\\nStatistics per sense\")\n",
    "print(sentences[sentences.is_valid].groupby(['main_lemma', 'sense']).first()['sense_sentence_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
