{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = 'experiment0'\n",
    "results_path = '../../results/%s' % experiment\n",
    "classifiers = ['baseline', 'decision_tree', 'log', 'mlp_5000', 'naive_bayes', 'svm']\n",
    "representations = ['handcrafted', 'hashed', 'negative_hashed']\n",
    "corpora = ['sensem', 'semeval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "labels = []\n",
    "labels_count = []\n",
    "\n",
    "for classifier, representation, corpus in\\\n",
    "    tqdm_notebook(product(*(classifiers, representations, corpora)),\n",
    "                  total=len(classifiers)*len(representations)*len(corpora)):\n",
    "    try:\n",
    "        path = os.path.join(results_path, '%s.csv' % ('_'.join([classifier, representation, corpus])))\n",
    "        df = pd.read_csv(path)\n",
    "    except OSError:\n",
    "        continue\n",
    "    \n",
    "    for (lemma, corpus_split), lcdf in df.groupby(['lemma', 'corpus'], sort=False):\n",
    "        if corpus_split == 'train':\n",
    "            labels, labels_count = np.unique(lcdf.true, return_counts=True)\n",
    "        \n",
    "        rdf = {'lemma': lemma, 'corpus': '%s.%s' % (corpus, corpus_split), 'num_classes': labels.shape[0],\n",
    "               'classifier': classifier, 'representation': representation}\n",
    "        rdf['accuracy'] = accuracy_score(lcdf.true, lcdf.prediction)\n",
    "        rdf['macro_precision'], rdf['macro_recall'], _, _ =\\\n",
    "            precision_recall_fscore_support(lcdf.true, lcdf.prediction, average='macro')\n",
    "        rdf['micro_precision'], rdf['micro_recall'], _, _ =\\\n",
    "            precision_recall_fscore_support(lcdf.true, lcdf.prediction, average='micro')\n",
    "        rdf['weighted_precision'], rdf['weighted_recall'], _, _ =\\\n",
    "            precision_recall_fscore_support(lcdf.true, lcdf.prediction, average='weighted')\n",
    "\n",
    "        if labels.shape[0] > 1:\n",
    "            precision, recall, _, _ =\\\n",
    "                precision_recall_fscore_support(lcdf.true, lcdf.prediction, average=None, labels=labels)\n",
    "            mask = np.ones(recall.shape, dtype=np.bool)\n",
    "            mask[np.argmax(recall)] = False\n",
    "            rdf['pmfc'] = precision[~mask][0]\n",
    "            rdf['rmlfc'] = recall[mask].mean()\n",
    "        else:  # Ill defined metrics for such case\n",
    "            rdf['pmfc'] = np.nan\n",
    "            rdf['rmlfc'] = np.nan\n",
    "        \n",
    "        results.append(rdf)\n",
    "\n",
    "columns = ['classifier', 'representation', 'lemma', 'num_classes', 'corpus', 'accuracy',\n",
    "           'macro_precision', 'macro_recall', 'pmfc', 'rmlfc', 'micro_precision', 'micro_recall',\n",
    "           'weighted_precision', 'weighted_recall']\n",
    "\n",
    "results = pd.DataFrame(results, columns=columns)\n",
    "results.to_csv('./data/%s.csv' % experiment, index=False, float_format='%.2e')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "f4cb2d0622124659b636f498af4cf8a0": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
